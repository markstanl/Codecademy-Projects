{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Methods\n",
    "\n",
    "In this project, you'll analyze data from a survey conducted by Fabio Mendoza Palechor and Alexis de la Hoz Manotas that asked people about their eating habits and weight. The data was obtained from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Estimation+of+obesity+levels+based+on+eating+habits+and+physical+condition+). Categorical variables were changed to numerical ones in order to facilitate analysis.\n",
    "\n",
    "First, you'll fit a logistic regression model to try to predict whether survey respondents are obese based on their answers to questions in the survey. After that, you'll use three different wrapper methods to choose a smaller feature subset.\n",
    "\n",
    "You'll use sequential forward selection, sequential backward floating selection, and recursive feature elimination. After implementing each wrapper method, you'll evaluate the model accuracy on the resulting smaller feature subsets and compare that with the model accuracy using all available features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "%matplotlib inline"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Logistic Regression Model\n",
    "\n",
    "The data set `obesity` contains 18 predictor variables. Here's a brief description of them.\n",
    "\n",
    "* `Gender` is `1` if a respondent is male and `0` if a respondent is female.\n",
    "* `Age` is a respondent's age in years.\n",
    "* `family_history_with_overweight` is `1` if a respondent has family member who is or was overweight, `0` if not.\n",
    "* `FAVC` is `1` if a respondent eats high caloric food frequently, `0` if not.\n",
    "* `FCVC` is `1` if a respondent usually eats vegetables in their meals, `0` if not.\n",
    "* `NCP` represents how many main meals a respondent has daily (`0` for 1-2 meals, `1` for 3 meals, and `2` for more than 3 meals).\n",
    "* `CAEC` represents how much food a respondent eats between meals on a scale of `0` to `3`.\n",
    "* `SMOKE` is `1` if a respondent smokes, `0` if not.\n",
    "* `CH2O` represents how much water a respondent drinks on a scale of `0` to `2`.\n",
    "* `SCC` is `1` if a respondent monitors their caloric intake, `0` if not.\n",
    "* `FAF` represents how much physical activity a respondent does on a scale of `0` to `3`.\n",
    "* `TUE` represents how much time a respondent spends looking at devices with screens on a scale of `0` to `2`.\n",
    "* `CALC` represents how often a respondent drinks alcohol on a scale of `0` to `3`.\n",
    "* `Automobile`, `Bike`, `Motorbike`, `Public_Transportation`, and `Walking` indicate a respondent's primary mode of transportation. Their primary mode of transportation is indicated by a `1` and the other columns will contain a `0`.\n",
    "\n",
    "The outcome variable, `NObeyesdad`, is a `1` if a patient is obese and a `0` if not.\n",
    "\n",
    "Use the `.head()` method and inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "obesity = pd.read_csv(\"obesity.csv\")\n",
    "\n",
    "# Inspect the data\n",
    "obesity.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into `X` and `y`\n",
    "\n",
    "In order to use a linear regression model, you'll need to split the data into two parts: the predictor variables and an outcome variable. Do this by splitting the data into a DataFrame of predictor variables called `X` and a Series of outcome variables `y`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X = obesity.drop([\"NObeyesdad\"], axis=1)\n",
    "y = obesity['NObeyesdad']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model\n",
    "\n",
    "Create a logistic regression model called `lr`. Include the parameter `max_iter=1000` to make sure that the model will converge when you try to fit it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lr = LogisticRegression(max_iter=1000)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Use the `.fit()` method on `lr` to fit the model to `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lr.fit(X, y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy\n",
    "\n",
    "A model's _accuracy_ is the proportion of classes that the model correctly predicts. Compute and print the accuracy of `lr` by using the `.score()` method. What percentage of respondents did the model correctly predict as being either obese or not obese? You may want to write this number down somewhere so that you can refer to it during future tasks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "og_score = lr.score(X, y)\n",
    "print(f\"Original Model Accuracy: {og_score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Forward Selection\n",
    "\n",
    "Now that you've created a logistic regression model and evaluated its performance, you're ready to do some feature selection.\n",
    "\n",
    "Create a sequential forward selection model called `sfs`.\n",
    "* Be sure to set the `estimator` parameter to `lr` and set the `forward` and `floating` parameters to the appropriate values.\n",
    "* Also use the parameters `k_features=9`, `scoring='accuracy'`, and `cv=0`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sfs = SFS(lr, forward=True, floating=False, k_features=9, scoring='accuracy', cv=0)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Use the `.fit()` method on `sfs` to fit the model to `X` and `y`. This step will take some time (not more than a minute) to run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sfs.fit(X, y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results\n",
    "\n",
    "Now that you've run the sequential forward selection algorithm on the logistic regression model with `X` and `y` you can see what features were chosen and check the model accuracy on the smaller feature set. Print `sfs.subsets_[9]` to see which features were chosen."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sfs.subsets_[9]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "\n",
    "Use the `plot_sfs()` function to plot the performance of the sequential forward selection model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller feature subset accuracy\n",
    "\n",
    "Compute and print the model accuracy using only the features selected by `sfs`. How does this accuracy compare to the accuracy of the model using all features?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_sfs = X[list(sfs.k_feature_names_)]\n",
    "lr.fit(X_sfs, y)\n",
    "sfs_score = lr.score(X_sfs, y)\n",
    "print(f\"SFS Model Accuracy: {sfs_score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Backward Floating Selection\n",
    "\n",
    "Use the same steps as above to perform sequential backward floating selection. Be sure to set the `forward` and `floating` parameters correctly."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sbfs = SFS(lr, forward=False, floating=True, k_features=9, scoring='accuracy', cv=0)\n",
    "sbfs.fit(X, y)\n",
    "sbfs.subsets_[9]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results\n",
    "\n",
    "Use the `plot_sfs()` function to plot the performance of the sequential backward floating selection model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_sfs(sbfs.get_metric_dict(), kind='std_err')\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller feature subset accuracy\n",
    "\n",
    "Compute and print the model accuracy using only the features selected by `sbfs`. How does this accuracy compare to the accuracy of the model using all features?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_sbfs = X[list(sbfs.k_feature_names_)]\n",
    "lr.fit(X_sbfs, y)\n",
    "sbfs_score = lr.score(X_sbfs, y)\n",
    "print(f\"SBFS Model Accuracy: {sbfs_score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "\n",
    "Now you'll use a recursive feature elimination model. Start by creating a `StandardScaler` object called `scaler`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the scaler\n",
    "\n",
    "Use the `.fit()` method to fit `scaler` to `X`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler.fit(X)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data\n",
    "\n",
    "Use the `.transform()` method to scale `X`. Save the transformed data to a variable called `X_scaled`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_scaled = scaler.transform(X)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "\n",
    "Create an `RFE` object called `rfe` and pass `lr` as the estimator. Use the parameter `n_features_to_select=9`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rfe = RFE(estimator=lr, n_features_to_select=9)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "\n",
    "Use the `.fit()` method on `rfe` to fit the model to `X_scaled` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rfe.fit(X_scaled, y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model accuracy\n",
    "\n",
    "Compute and print the model accuracy using only the features selected by `rfe`. How does this accuracy compare to the accuracy of the model using all features?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X_rfe = X_scaled[:, rfe.support_]\n",
    "lr.fit(X_rfe, y)\n",
    "rfe_score = lr.score(X_rfe, y)\n",
    "print(f\"RFE Model Accuracy: {rfe_score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've now used three different wrapper methods to select features for a logistic regression model. Print out the accuracy of the original model, and the models using features selected by sequential forward selection, sequential backward floating selection, and recursive feature elimination. \n",
    "\n",
    "How do these accuracies compare? Which method resulted in the smallest feature subset? Which method resulted in the highest accuracy? Finally, if you had to choose a feature selection method to use in practice, which one would you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Original Model Accuracy: {og_score:.4f}\")\n",
    "print(f\"SFS Model Accuracy: {sfs_score:.4f}\")\n",
    "print(f\"SBFS Model Accuracy: {sbfs_score:.4f}\")\n",
    "print(f\"RFE Model Accuracy: {rfe_score:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
